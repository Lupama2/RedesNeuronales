{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 4\n",
    "\n",
    "## Ejercicio 1\n",
    "\n",
    "En el algoritmo de back-propagation, en la fórmula (6.18) del Herz, es necesario agregar sobre h una componente extra que puede ser escencialmente cualquier cosa. ¿Por qué es necesario agregarla? Viene del hecho de que la neurona bias no tiene ningún input, pero las demás sí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importo dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defino datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Def regla XOR\n",
    "def XOR(x1, x2):\n",
    "    #x1, x2: +1 o -1\n",
    "    return x1 * x2\n",
    "\n",
    "#Def datos x e y\n",
    "x_data = np.empty([4, 2])\n",
    "y_data = np.empty(4)\n",
    "\n",
    "x_data[0] = np.array([1,1])\n",
    "x_data[1] = np.array([1,-1])\n",
    "x_data[2] = np.array([-1,1])\n",
    "x_data[3] = np.array([-1,-1])\n",
    "\n",
    "for i in range(len(y_data)):\n",
    "    y_data[i] = XOR(x_data[i][0], x_data[i][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defino funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Def la aplicación de una red\n",
    "def red_forward(x_test, red):\n",
    "    V_0 = np.concatenate((x_test, np.array([-1])), axis = 0) #Agrego el bias 3x1\n",
    "    for j in range(len(red[\"pesos\"])):\n",
    "        w = red[\"pesos\"][j]\n",
    "        h = np.dot(w.T, V_0)\n",
    "        if j != len(red[\"pesos\"]) - 1:\n",
    "            V_1 = np.concatenate((g(h), np.array([-1])), axis = 0) #3x1\n",
    "        else: #Si estoy en la última capa\n",
    "            V_1 = g(h)\n",
    "        V_0 = V_1\n",
    "    return V_1[0]\n",
    "\n",
    "#Def función de validación\n",
    "def validacion(x_test, y_test, red):\n",
    "    error = 0\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        #Forward pass\n",
    "        y_out = red_forward(x_test[i], red)\n",
    "\n",
    "        #Calculo el error\n",
    "        #y_out está entre -1 y 1. Lo llevo a 0 y 1 y luego lo vuelov a -1 y 1\n",
    "        y_out_round = round((y_out + 1)/2)* 2 - 1\n",
    "        error += y_test[i] - y_out_round\n",
    "\n",
    "    return error/len(y_test)\n",
    "\n",
    "def e_loss(x_test, y_test, red):\n",
    "    error = 0\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        #Forward pass\n",
    "        y_out = red_forward(x_test[i], red)\n",
    "\n",
    "        #Calculo el error\n",
    "        error += (y_test[i] - y_out)**2\n",
    "\n",
    "    return error/2\n",
    "\n",
    "#Def función de transferencia\n",
    "def g(h_vec):\n",
    "\n",
    "    return np.tanh(h_vec)\n",
    "\n",
    "def g_prima(h_vec):\n",
    "    return 1 - g(h_vec)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Def redes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ini_max = 0.1\n",
    "red_A = {\"input\":2, \"hidden\":2, \"output\":1, \"pesos\":[np.random.rand(3,2)*w_ini_max, np.random.rand(3,1)*w_ini_max]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back-propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Def algoritmo de retropropagación de errores\n",
    "def back_propagation(x_data, y_data, red, eta):\n",
    "    #Se usa la nomenclatura del Hertz\n",
    "\n",
    "    #Loop sobre las muestras\n",
    "    for i in range(len(y_data)):   \n",
    "        #Forward pass\n",
    "        V_0 = np.concatenate((x_data[i], np.array([-1])), axis = 0) #Agrego el bias 3x1\n",
    "        w_1 = red[\"pesos\"][0] #3x2\n",
    "        h_1 = np.dot(w_1.T, V_0) #2x1\n",
    "        V_1 = np.concatenate((g(h_1), np.array([-1])), axis = 0) #3x1\n",
    "\n",
    "        w_2 = red[\"pesos\"][1] #3x1\n",
    "        h_2 = np.dot(w_2.T, V_1) #1x1\n",
    "        V_2 = g(h_2) #1x1\n",
    "\n",
    "        #Backward\n",
    "        #Calculo el error de la capa de salida\n",
    "        delta_2 = g_prima(h_2)*(y_data[i] - V_2) #1x1\n",
    "\n",
    "        #Calculo el error de la capa oculta\n",
    "        # delta_1 = g_prima(h_1)*np.dot(w_2, delta_2) #\n",
    "        delta_1 = np.concatenate([g_prima(h_1),np.array([1])])*np.dot(w_2, delta_2) #3x1\n",
    "\n",
    "        #Actualizo pesos\n",
    "        w_1 += eta * np.outer(V_0, delta_1[:2]) #3x2\n",
    "        w_2 += eta * np.outer(V_1, delta_2)\n",
    "\n",
    "        red[\"pesos\"] = [w_1, w_2]\n",
    "\n",
    "    return red\n",
    "\n",
    "#Def algoritmo de aprendizaje\n",
    "def aprendizaje(x_data, y_data, red, eta, epochs = 1):\n",
    "    #Def array de errores\n",
    "    e_loss_vec = np.empty(epochs)\n",
    "    validacion_vec = np.empty(epochs)\n",
    "\n",
    "    #Loop sobre las epochs\n",
    "    for i in range(epochs):\n",
    "        #Backpropagation\n",
    "        red = back_propagation(x_data, y_data, red, eta)\n",
    "        \n",
    "        #Cálculo de errores\n",
    "        e_loss_vec[i] = e_loss(x_data, y_data, red)\n",
    "        validacion_vec[i] = validacion(x_data, y_data, red)\n",
    "\n",
    "\n",
    "    return red, e_loss_vec, validacion_vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entreno red A\n",
    "eta = 0.1\n",
    "model_A = aprendizaje(x_data, y_data, red_A, eta, epochs = 100)\n",
    "\n",
    "#Entreno red B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FISCOM2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
